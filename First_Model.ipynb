{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (learn-env)",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCherryA050/phase_4_project/blob/main/First_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8CMJxg1sqS2"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnXxPBsVsqS4",
        "outputId": "4fee6050-f1af-43c4-9e0b-4c29e670fcfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run for Google Colab environment\n",
        "!pip install pyspark\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "!pip install mlflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 71kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 22.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=a9bb4728e4119634e5ac1f16d79ca533611d691889e53181e591e309bc1a6c2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 160815 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/c9/190a45e667b63edb76112deefa70629c2d9985603a85cb1968015fe0f327/mlflow-1.18.0-py3-none-any.whl (14.2MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2MB 221kB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/af/631375abc29e59cedfa4467a5f7755503ba19898890751e1f2636ef02f92/databricks-cli-0.14.3.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/c1/2cc385fadf18dc75fe24c18899269eda4dcc60221d61eff7da4a6cc5c01d/prometheus_flask_exporter-0.18.2.tar.gz\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (20.9)\n",
            "Collecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/5a/f988909dfed18c1ac42ad8d9e611e6c5657e270aa6eb68559985dbb69c13/docker-5.0.0-py2.py3-none-any.whl (146kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Collecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.4MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 54.7MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.20)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Collecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from querystring-parser->mlflow) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mlflow) (2.8.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (2.4.7)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5f/3c211d168b2e9f9342cfb53bcfc26aab0eac63b998015e7af7bcae66119d/websocket_client-1.1.0-py2.py3-none-any.whl (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn; platform_system != \"Windows\"->mlflow) (57.0.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (4.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.1MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy->mlflow) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Building wheels for collected packages: databricks-cli, prometheus-flask-exporter, alembic\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-cp37-none-any.whl size=100560 sha256=21b089ca5392e3c04752cebef8052293332ee7a1323d9fe65f9d36cc275994de\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/24/f3/34d8e3964dac4ba849d844273c49a679111b00d5799ebb934a\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-cp37-none-any.whl size=17415 sha256=ea40e15d7604824309b75b9a7930d8bca4ce452c375f8117296c548a9f5214dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e2/9c/4f3ee23964802940f81a8b476d0b9be6fb6348cb12df2e2226\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=e3bfb0360d350c64ac56ad4bccdbdc740ccbf6bc1243ca4781202bf38ce5ab88\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "Successfully built databricks-cli prometheus-flask-exporter alembic\n",
            "Installing collected packages: querystring-parser, databricks-cli, prometheus-flask-exporter, websocket-client, docker, gunicorn, smmap, gitdb, gitpython, pyyaml, Mako, python-editor, alembic, mlflow\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed Mako-1.1.4 alembic-1.4.1 databricks-cli-0.14.3 docker-5.0.0 gitdb-4.0.7 gitpython-3.1.18 gunicorn-20.1.0 mlflow-1.18.0 prometheus-flask-exporter-0.18.2 python-editor-1.0.4 pyyaml-5.4.1 querystring-parser-1.2.4 smmap-4.0.0 websocket-client-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs3k8BdsstrD"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import feature\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "# import org.apache.spark.sql.functions.col\n",
        "# import org.apache.spark.sql.types.IntegerType\n",
        "# import pyspark.sql.functions.col\n",
        "from pyspark.sql.types import IntegerType"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q-0oziytrod"
      },
      "source": [
        "spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .appName('anime_rec').config('spark.driver.host', 'localhost')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN6p3aIWtCOs"
      },
      "source": [
        "rec_data = spark.read.csv('animelist.csv', header='true')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M2a5rActmWK"
      },
      "source": [
        "\n",
        "rec_data = rec_data.withColumn('rating', rec_data['rating'].cast(IntegerType()))\n",
        "rec_data = rec_data.withColumn('user_id', rec_data['user_id'].cast(IntegerType()))\n",
        "rec_data = rec_data.withColumn('anime_id', rec_data['anime_id'].cast(IntegerType()))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rstj-AYJt_h3",
        "outputId": "f06ef096-6f31-4238-d263-0ff818cb5ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rec_data.dtypes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user_id', 'int'),\n",
              " ('anime_id', 'int'),\n",
              " ('rating', 'int'),\n",
              " ('watching_status', 'string'),\n",
              " ('watched_episodes', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWi-85ODw8Va"
      },
      "source": [
        "rec_data = rec_data.drop('watching_status')\n",
        "rec_data = rec_data.drop('watched_episodes')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA6olC_TxEhG",
        "outputId": "4aa99013-f2d1-40a1-d72c-460a0b347948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rec_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: int, anime_id: int, rating: int]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2fEfTHyxMuo"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "(training, test) = rec_data.randomSplit([0.8, 0.2], seed=1)\n",
        "\n",
        "als = ALS(maxIter=5, rank=10, regParam=0.01, userCol='user_id', itemCol='anime_id', ratingCol='rating', coldStartStrategy ='drop')\n",
        "# fit the ALS model to the training set\n",
        "model = als.fit(training)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts3MoklAxpO6",
        "outputId": "922f1ffd-bf02-453e-d87a-128638b3469c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# importing appropriate library\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print('Root-mean-square error = ' + str(rmse))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root-mean-square error = 3.13945031256278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Hz1P9cKbaZ"
      },
      "source": [
        "# Takes about an hour to run\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# initialize the ALS model\n",
        "als_model = ALS(userCol='user_id', itemCol='anime_id', ratingCol='rating', coldStartStrategy='drop')\n",
        "\n",
        "# create the parameter grid              \n",
        "params = ParamGridBuilder()\\\n",
        "  .addGrid(als_model.regParam, [0.01, 0.001, 0.1])\\\n",
        "  .addGrid(als_model.rank, [10]).build() # Ran earlier and found 10 to be best\n",
        "\n",
        "# instantiating crossvalidator estimator\n",
        "cv = CrossValidator(estimator=als_model, estimatorParamMaps=params, evaluator=evaluator, parallelism=4)\n",
        "best_model = cv.fit(rec_data)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sBXkCXUkOr9",
        "outputId": "fafa6f4e-5e6e-463b-95c7-feee5ee735d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# We see the best model has a rank of 10, so we will use that in our future models with this dataset\n",
        "print(best_model.bestModel.rank)\n",
        "print(best_model.bestModel.getParam())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d1076c1e1900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We see the best model has a rank of 10, so we will use that in our future models with this dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'regParam' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5xAjDm-KxaO",
        "outputId": "8d725967-28d1-4df4-c690-45024ad51d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "anime_titles = spark.read.csv('anime.csv', header=True)\n",
        "anime_titles.head(5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(MAL_ID='1', Name='Cowboy Bebop', Score='8.78', Genders='Action, Adventure, Comedy, Drama, Sci-Fi, Space', English name='Cowboy Bebop', Japanese name='カウボーイビバップ', Type='TV', Episodes='26', Aired='Apr 3, 1998 to Apr 24, 1999', Premiered='Spring 1998', Producers='Bandai Visual', Licensors='Funimation, Bandai Entertainment', Studios='Sunrise', Source='Original', Duration='24 min. per ep.', Rating='R - 17+ (violence & profanity)', Ranked='28.0', Popularity='39', Members='1251960', Favorites='61971', Watching='105808', Completed='718161', On-Hold='71513', Dropped='26678', Plan to Watch='329800', Score-10='229170.0', Score-9='182126.0', Score-8='131625.0', Score-7='62330.0', Score-6='20688.0', Score-5='8904.0', Score-4='3184.0', Score-3='1357.0', Score-2='741.0', Score-1='1580.0'),\n",
              " Row(MAL_ID='5', Name='Cowboy Bebop: Tengoku no Tobira', Score='8.39', Genders='Action, Drama, Mystery, Sci-Fi, Space', English name='Cowboy Bebop:The Movie', Japanese name='カウボーイビバップ 天国の扉', Type='Movie', Episodes='1', Aired='Sep 1, 2001', Premiered='Unknown', Producers='Sunrise, Bandai Visual', Licensors='Sony Pictures Entertainment', Studios='Bones', Source='Original', Duration='1 hr. 55 min.', Rating='R - 17+ (violence & profanity)', Ranked='159.0', Popularity='518', Members='273145', Favorites='1174', Watching='4143', Completed='208333', On-Hold='1935', Dropped='770', Plan to Watch='57964', Score-10='30043.0', Score-9='49201.0', Score-8='49505.0', Score-7='22632.0', Score-6='5805.0', Score-5='1877.0', Score-4='577.0', Score-3='221.0', Score-2='109.0', Score-1='379.0'),\n",
              " Row(MAL_ID='6', Name='Trigun', Score='8.24', Genders='Action, Sci-Fi, Adventure, Comedy, Drama, Shounen', English name='Trigun', Japanese name='トライガン', Type='TV', Episodes='26', Aired='Apr 1, 1998 to Sep 30, 1998', Premiered='Spring 1998', Producers='Victor Entertainment', Licensors='Funimation, Geneon Entertainment USA', Studios='Madhouse', Source='Manga', Duration='24 min. per ep.', Rating='PG-13 - Teens 13 or older', Ranked='266.0', Popularity='201', Members='558913', Favorites='12944', Watching='29113', Completed='343492', On-Hold='25465', Dropped='13925', Plan to Watch='146918', Score-10='50229.0', Score-9='75651.0', Score-8='86142.0', Score-7='49432.0', Score-6='15376.0', Score-5='5838.0', Score-4='1965.0', Score-3='664.0', Score-2='316.0', Score-1='533.0'),\n",
              " Row(MAL_ID='7', Name='Witch Hunter Robin', Score='7.27', Genders='Action, Mystery, Police, Supernatural, Drama, Magic', English name='Witch Hunter Robin', Japanese name='Witch Hunter ROBIN (ウイッチハンターロビン)', Type='TV', Episodes='26', Aired='Jul 2, 2002 to Dec 24, 2002', Premiered='Summer 2002', Producers='TV Tokyo, Bandai Visual, Dentsu, Victor Entertainment', Licensors='Funimation, Bandai Entertainment', Studios='Sunrise', Source='Original', Duration='25 min. per ep.', Rating='PG-13 - Teens 13 or older', Ranked='2481.0', Popularity='1467', Members='94683', Favorites='587', Watching='4300', Completed='46165', On-Hold='5121', Dropped='5378', Plan to Watch='33719', Score-10='2182.0', Score-9='4806.0', Score-8='10128.0', Score-7='11618.0', Score-6='5709.0', Score-5='2920.0', Score-4='1083.0', Score-3='353.0', Score-2='164.0', Score-1='131.0'),\n",
              " Row(MAL_ID='8', Name='Bouken Ou Beet', Score='6.98', Genders='Adventure, Fantasy, Shounen, Supernatural', English name='Beet the Vandel Buster', Japanese name='冒険王ビィト', Type='TV', Episodes='52', Aired='Sep 30, 2004 to Sep 29, 2005', Premiered='Fall 2004', Producers='TV Tokyo, Dentsu', Licensors='Unknown', Studios='Toei Animation', Source='Manga', Duration='23 min. per ep.', Rating='PG - Children', Ranked='3710.0', Popularity='4369', Members='13224', Favorites='18', Watching='642', Completed='7314', On-Hold='766', Dropped='1108', Plan to Watch='3394', Score-10='312.0', Score-9='529.0', Score-8='1242.0', Score-7='1713.0', Score-6='1068.0', Score-5='634.0', Score-4='265.0', Score-3='83.0', Score-2='50.0', Score-1='27.0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZGzLULlfzyf"
      },
      "source": [
        "def name_retriever(anime_id, dataframe=anime_titles):\n",
        "    return anime_titles.where(anime_titles.MAL_ID == anime_id).take(1)[0]['Name']"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYYubwQOhoRT",
        "outputId": "24571bf9-a5cb-4cf3-e4e1-d5b65d9d9569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(name_retriever(1, anime_titles))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cowboy Bebop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7_g3IsChqsv"
      },
      "source": [
        "users = rec_data.select(als.getUserCol()).distinct().limit(1)\n",
        "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
        "recs = userSubsetRecs.take(1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9t0mietidNG",
        "outputId": "cb17b1ec-cb11-4eac-e321-d26004a277da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# use indexing to obtain the movie id of top predicted rated item\n",
        "first_recommendation = recs[0]['recommendations'][0][0]\n",
        "\n",
        "# use the name retriever function to get the values\n",
        "name_retriever(first_recommendation,anime_titles)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Kindaichi Shounen no Jikenbo Movie 1: Operazakan - Aratanaru Satsujin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0YNAeqzm2lf",
        "outputId": "47b18e3c-8b94-41a2-9024-5cc7a7ae6c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "recommendations = model.recommendForAllUsers(5)\n",
        "recommendations.where(recommendations.user_id == 3).collect()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id=3, recommendations=[Row(anime_id=28251, rating=21.12415885925293), Row(anime_id=40639, rating=18.66773223876953), Row(anime_id=3444, rating=18.416454315185547), Row(anime_id=928, rating=16.966115951538086), Row(anime_id=41260, rating=16.548372268676758)])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkb0iK3pnQ12"
      },
      "source": [
        "def new_user_recs(user_id, new_ratings, rating_df, anime_title_df, num_recs):\n",
        "    # turn the new_recommendations list into a spark DataFrame\n",
        "    new_user_ratings = spark.createDataFrame(new_ratings, rating_df.columns)\n",
        "    \n",
        "    # combine the new ratings df with the rating_df\n",
        "    anime_ratings_combined = rating_df.union(new_user_ratings)\n",
        "    \n",
        "    # create an ALS model and fit it\n",
        "    als = ALS(maxIter=5, rank=10, regParam=0.01, userCol='user_id', itemCol='anime_id', ratingCol='rating',\n",
        "              coldStartStrategy='drop')\n",
        "    model = als.fit(anime_ratings_combined)\n",
        "    \n",
        "    # make recommendations for all users using the recommendForAllUsers method\n",
        "    recommendations = model.recommendForAllUsers(num_recs)\n",
        "    \n",
        "    # get recommendations specifically for the new user that has been added to the DataFrame\n",
        "    recs_for_user = recommendations.where(recommendations.user_id == user_id).take(1)\n",
        "\n",
        "    for ranking, (anime_id, rating) in enumerate(recs_for_user[0]['recommendations']):\n",
        "      anime_string = name_retriever(anime_id, anime_title_df)\n",
        "      print('Recommendation {}: {}  | predicted score: {}'.format(ranking+1, anime_string, rating))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70kpfLJmnQ-p",
        "outputId": "cdda3258-f5b1-4cbb-8ad8-67e2e2266c97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "user_id = 1000000\n",
        "user_ratings_1 = [(user_id,3253,5),\n",
        "                  (user_id,2459,5),\n",
        "                  (user_id,2513,4),\n",
        "                  (user_id,6502,5),\n",
        "                  (user_id,1091,5),\n",
        "                  (user_id,441,4)]\n",
        "new_user_recs(user_id,\n",
        "             new_ratings=user_ratings_1,\n",
        "             rating_df=rec_data,\n",
        "             anime_title_df=anime_titles,\n",
        "             num_recs = 10)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recommendation 1: Kanojo ga Kanji wo Suki na Riyuu.  | predicted score: 16.453216552734375\n",
            "Recommendation 2: Universe  | predicted score: 15.597274780273438\n",
            "Recommendation 3: 1/100 Train Station  | predicted score: 14.501545906066895\n",
            "Recommendation 4: Attakai, Fuyu Canada  | predicted score: 13.245718002319336\n",
            "Recommendation 5: Code Geass: Hangyaku no Lelouch Picture Drama - Kiseki no Anniversary  | predicted score: 13.189346313476562\n",
            "Recommendation 6: 1/100 Shibuya Crossing  | predicted score: 12.995405197143555\n",
            "Recommendation 7: 1/100 Rice Planting  | predicted score: 12.851329803466797\n",
            "Recommendation 8: Kimagure Mercy  | predicted score: 12.703506469726562\n",
            "Recommendation 9: Re Boot  | predicted score: 12.488151550292969\n",
            "Recommendation 10: Tokimeki Runners  | predicted score: 12.397653579711914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliC0lUdnRDd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOdrXvkDnRHC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}